{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4200842 (16.02 MB)\n",
      "Trainable params: 4200842 (16.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 9s 26ms/step - loss: 1.8636 - accuracy: 0.3428 - val_loss: 1.5166 - val_accuracy: 0.4602\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 1.4560 - accuracy: 0.4829 - val_loss: 1.4014 - val_accuracy: 0.5181\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.3236 - accuracy: 0.5304 - val_loss: 1.2172 - val_accuracy: 0.5800\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.2323 - accuracy: 0.5656 - val_loss: 1.1865 - val_accuracy: 0.5882\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 1.1576 - accuracy: 0.5933 - val_loss: 1.2042 - val_accuracy: 0.5862\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.0997 - accuracy: 0.6140 - val_loss: 1.1351 - val_accuracy: 0.6073\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.0496 - accuracy: 0.6287 - val_loss: 1.0324 - val_accuracy: 0.6442\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.9958 - accuracy: 0.6522 - val_loss: 1.0670 - val_accuracy: 0.6261\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.9556 - accuracy: 0.6652 - val_loss: 0.9945 - val_accuracy: 0.6607\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.9185 - accuracy: 0.6759 - val_loss: 1.0357 - val_accuracy: 0.6514\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.8776 - accuracy: 0.6930 - val_loss: 1.0583 - val_accuracy: 0.6310\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.8462 - accuracy: 0.7039 - val_loss: 0.9758 - val_accuracy: 0.6672\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.8094 - accuracy: 0.7165 - val_loss: 1.0021 - val_accuracy: 0.6646\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.7764 - accuracy: 0.7273 - val_loss: 1.0173 - val_accuracy: 0.6562\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.7469 - accuracy: 0.7390 - val_loss: 1.0222 - val_accuracy: 0.6612\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.7171 - accuracy: 0.7513 - val_loss: 0.9695 - val_accuracy: 0.6777\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.6890 - accuracy: 0.7587 - val_loss: 1.0377 - val_accuracy: 0.6622\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.6638 - accuracy: 0.7680 - val_loss: 1.0022 - val_accuracy: 0.6658\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.6339 - accuracy: 0.7798 - val_loss: 0.9617 - val_accuracy: 0.6858\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.6076 - accuracy: 0.7901 - val_loss: 0.9963 - val_accuracy: 0.6780\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 1.0069 - accuracy: 0.6671\n",
      "Test score: 1.006922960281372\n",
      "Test accuracy: 0.6671000123023987\n"
     ]
    }
   ],
   "source": [
    "#            Joel De Alba \n",
    "#  Southern New Hampshire University\n",
    "#      Professor Timothy lexander\n",
    "#            08 / 02 / 23\n",
    "\n",
    "# AI Deep Learning Image Processing Implements (CIFAR-10 Dataset)\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras import utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The CIFAR-10 dataset contains 60,000 color images of 32x32 pixels \n",
    "# (3 Channels / 10 Classes) - Below is the code for the channels\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# Below is the code for the Pixels Preset\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "# Constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "# load Dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert to categorical (One-Hot encoding utilized to normalize the images)\n",
    "Y_train = utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# Float and Normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', input_shape = (IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu')) # Rectified Linear Unit Activation Type\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu')) # Rectified Linear Unit Activation Type\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax')) # Softmax Unit Activation Type\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=OPTIM, metrics = ['accuracy'])\n",
    "model.fit(X_train , Y_train, batch_size = BATCH_SIZE, epochs = NB_EPOCH, validation_split = VALIDATION_SPLIT, verbose = VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test, batch_size = BATCH_SIZE, verbose = VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "\n",
    "# weights learned\n",
    "model.save_weights('cifar10_weights.h5', overwrite = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1676842 (6.40 MB)\n",
      "Trainable params: 1676842 (6.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 1.8392 - accuracy: 0.3327 - val_loss: 1.4948 - val_accuracy: 0.4519\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 1.4232 - accuracy: 0.4906 - val_loss: 1.1789 - val_accuracy: 0.5824\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 1.1970 - accuracy: 0.5757 - val_loss: 1.0403 - val_accuracy: 0.6215\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 1.0572 - accuracy: 0.6267 - val_loss: 1.0909 - val_accuracy: 0.6184\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.9437 - accuracy: 0.6708 - val_loss: 0.9116 - val_accuracy: 0.6789\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.8643 - accuracy: 0.6970 - val_loss: 0.8995 - val_accuracy: 0.6775\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.7917 - accuracy: 0.7236 - val_loss: 1.0246 - val_accuracy: 0.6728\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.7386 - accuracy: 0.7448 - val_loss: 0.7914 - val_accuracy: 0.7219\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.6842 - accuracy: 0.7601 - val_loss: 0.7208 - val_accuracy: 0.7498\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.6392 - accuracy: 0.7765 - val_loss: 0.6889 - val_accuracy: 0.7657\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.5944 - accuracy: 0.7933 - val_loss: 0.7216 - val_accuracy: 0.7585\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.5598 - accuracy: 0.8063 - val_loss: 0.6507 - val_accuracy: 0.7772\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.5296 - accuracy: 0.8153 - val_loss: 0.6837 - val_accuracy: 0.7745\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.4962 - accuracy: 0.8275 - val_loss: 0.7063 - val_accuracy: 0.7724\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.4660 - accuracy: 0.8374 - val_loss: 0.6761 - val_accuracy: 0.7731\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.4516 - accuracy: 0.8424 - val_loss: 0.7005 - val_accuracy: 0.7798\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.4322 - accuracy: 0.8500 - val_loss: 0.6493 - val_accuracy: 0.7904\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.4161 - accuracy: 0.8550 - val_loss: 0.7177 - val_accuracy: 0.7808\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.4047 - accuracy: 0.8590 - val_loss: 0.7149 - val_accuracy: 0.7912\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.3969 - accuracy: 0.8636 - val_loss: 0.7377 - val_accuracy: 0.7763\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.7684 - accuracy: 0.7607\n",
      "Test score: 0.7684239149093628\n",
      "Test accuracy: 0.760699987411499\n"
     ]
    }
   ],
   "source": [
    "#            Joel De Alba \n",
    "#  Southern New Hampshire University\n",
    "#      Professor Timothy lexander\n",
    "#            08 / 02 / 23\n",
    "\n",
    "# AI Deep Learning Image Processing Implements (CIFAR-10 Dataset)\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras import utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The CIFAR-10 dataset contains 60,000 color images of 32x32 pixels \n",
    "# (3 Channels / 10 Classes) - Below is the code for the channels\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# Below is the code for the Pixels Preset\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "# Constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "# load Dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert to categorical (One-Hot encoding utilized to normalize the images)\n",
    "Y_train = utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# Float and Normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', input_shape = (IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu')) # Rectified Linear Unit Activation Type\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
    "model.add(Activation('relu')) # Rectified Linear Unit Activation Type\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model.add(Activation('relu')) # Rectified Linear Unit Activation Type\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu')) # Rectified Linear Unit Activation Type\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu')) # Rectified Linear Unit Activation Type\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax')) # Softmax Unit Activation Type\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=OPTIM, metrics = ['accuracy'])\n",
    "model.fit(X_train , Y_train, batch_size = BATCH_SIZE, epochs = NB_EPOCH, validation_split = VALIDATION_SPLIT, verbose = VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test, batch_size = BATCH_SIZE, verbose = VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "\n",
    "# weights learned\n",
    "model.save_weights('cifar10_weights.h5', overwrite = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Additional Commentary Bellow\n",
    "\n",
    "The CIFAR-10 image classification algorithm presented here has broader applications beyond distinguishing\n",
    "between animals and vehicles. It is capable of processing images containing various objects and potentia-\n",
    "lly even human faces. However, using such an algorithm to distinguish people's faces raises several ethic-\n",
    "al and privacy concerns. \n",
    "\n",
    "Concerns involved are: Privacy concerns, Biases and Discrimination, Data Security, Informed Consent, Surv-\n",
    "eillance and Tracking, Unintended consequences, Function creep where processes exceed the intended data s-\n",
    "tore, false positives and negatives, Government and Corporate use, and other such concerns.\n",
    "\n",
    "To address these concerns, strict regulations and guidelines must be in place for the development, deploy-\n",
    "ment, and use of facial recognition algorithms. Transparency in algorithmic decision-making, regular audi-\n",
    "ts for bias and fairness, data protection measures, and clear consent mechanisms are some of the steps th-\n",
    "at can help mitigate these ethical and privacy implications.\n",
    "\n",
    "It is essential to engage in public discussions and debates on the ethical use of facial recognition tech-\n",
    "nology and involve multiple stakeholders, including policymakers, technologists, ethicists, and the gener-\n",
    "al public, to collectively shape the future of such technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
